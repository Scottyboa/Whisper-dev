<script>
document.addEventListener("DOMContentLoaded", function() {
  /* --------------------------
     Multi-language & Consent Banner Logic (Transcribe Page)
     -------------------------- */
  const transcribeTranslations = {
    en: {
      pageTitle: "Transcription Tool with Ads and Guide Overlay",
      openaiUsageLinkText: "Cost usage overview",
      btnFunctions: "Functions",
      btnGuide: "Guide",
      recordingAreaTitle: "Recording Area",
      recordTimer: "Recording Timer: 0 sec",
      uploadTimer: "Upload Timer: 0 sec",
      transcribeTimer: "Transcription Timer: 0 sec",
      transcriptionPlaceholder: "Transcription result will appear here...",
      startButton: "Start Recording",
      stopButton: "Stop/Complete",
      pauseButton: "Pause Recording",
      statusMessage: "Welcome! Click \"Start Recording\" to begin.",
      noteGenerationTitle: "Note Generation",
      generateNoteButton: "Generate Note",
      noteTimer: "Note Generation Timer: 0 sec",
      generatedNotePlaceholder: "Generated note will appear here...",
      customPromptTitle: "Custom Prompt",
      promptSlotLabel: "Prompt Slot:",
      customPromptPlaceholder: "Enter custom prompt here",
      adUnitText: "Your Ad Here",
      guideHeading: "Guide & Instructions",
      guideText: `Welcome to the Whisper Transcription tool. This application allows medical professionals, therapists, and other practitioners to record and transcribe consultations, as well as generate professional notes using an AI-powered note generator.
<br><br>
<strong>How to Use the Functions:</strong>
<ul>
  <li><strong>Recording:</strong> Click "Start Recording" to begin capturing audio. Click "Stop/Complete" to end recording and trigger transcript fetching via polling.</li>
  <li><strong>Polling Transcription:</strong> As each chunk is uploaded, the system automatically polls the backend until its transcript is ready and then merges them in order.</li>
  <li><strong>Note Generation:</strong> After transcription, click "Generate Note" to produce a note based on your transcript and custom prompt.</li>
  <li><strong>Custom Prompt:</strong> On the right, select a prompt slot (1–10) and enter your custom prompt. Your prompt is saved automatically and linked to your API key.</li>
  <li><strong>Guide Toggle:</strong> Use the "Functions" and "Guide" buttons to switch between the functional view and this guide. The guide appears as an overlay and does not disturb the underlying layout.</li>
</ul>
Please click "Functions" to return to the main interface.`
    },
    no: {
      pageTitle: "Transkripsjonsverktøy med annonser og veiledningsoverlegg",
      openaiUsageLinkText: "Vis OpenAI bruk",
      btnFunctions: "Funksjoner",
      btnGuide: "Veiledning",
      recordingAreaTitle: "Opptaksområde",
      recordTimer: "Opptakstimer: 0 sek",
      uploadTimer: "Opplastningstimer: 0 sek",
      transcribeTimer: "Transkripsjonstimer: 0 sek",
      transcriptionPlaceholder: "Transkripsjonsresultatet vises her...",
      startButton: "Start opptak",
      stopButton: "Stopp/Fullfør",
      pauseButton: "Pause opptak",
      statusMessage: "Velkommen! Klikk 'Start opptak' for å begynne.",
      noteGenerationTitle: "Notatgenerering",
      generateNoteButton: "Generer notat",
      noteTimer: "Notatgenereringstimer: 0 sek",
      generatedNotePlaceholder: "Generert notat vises her...",
      customPromptTitle: "Tilpasset melding",
      promptSlotLabel: "Meldingsplass:",
      customPromptPlaceholder: "Skriv inn tilpasset melding her",
      adUnitText: "Din annonse her",
      guideHeading: "Veiledning og Instruksjoner",
      guideText: `Velkommen til Whisper Transkripsjonsverktøy. Denne applikasjonen lar medisinske fagpersoner, terapeuter og andre utøvere ta opp og transkribere konsultasjoner, samt generere profesjonelle notater ved hjelp av en AI-drevet notatgenerator.
<br><br>
<strong>Slik bruker du verktøyet:</strong>
<ul>
  <li><strong>Opptak:</strong> Klikk på "Start opptak" for å starte opptaket. Klikk på "Stopp/Fullfør" for å avslutte opptaket og hente transkripsjonen via polling.</li>
  <li><strong>Polling Transkripsjon:</strong> Når hver lydchunk er lastet opp, henter systemet automatisk transkripsjonen til chunket og setter sammen resultatet i rekkefølge.</li>
  <li><strong>Notatgenerering:</strong> Etter transkripsjonen, klikk "Generer notat" for å lage et notat basert på transkripsjonen og din tilpassede melding.</li>
  <li><strong>Tilpasset melding:</strong> Velg et meldingsfelt (1–10) og skriv inn din tilpassede melding. Meldingen lagres automatisk og knyttes til din API-nøkkel.</li>
  <li><strong>Veiledning:</strong> Bruk knappene "Funksjoner" og "Veiledning" for å bytte mellom verktøysgrensesnittet og denne veiledningen.</li>
</ul>
Klikk "Funksjoner" for å gå tilbake til hovedskjermen.`
    }
  };
  
  function updateLanguageTranscribe(lang) {
    document.getElementById("page-title-transcribe").textContent = transcribeTranslations[lang].pageTitle;
    document.getElementById("openaiUsageLink").textContent = transcribeTranslations[lang].openaiUsageLinkText;
    document.getElementById("btnFunctions").textContent = transcribeTranslations[lang].btnFunctions;
    document.getElementById("btnGuide").textContent = transcribeTranslations[lang].btnGuide;
    document.getElementById("recordingAreaTitle").textContent = transcribeTranslations[lang].recordingAreaTitle;
    document.getElementById("recordTimer").textContent = transcribeTranslations[lang].recordTimer;
    document.getElementById("uploadTimer").textContent = transcribeTranslations[lang].uploadTimer;
    document.getElementById("transcribeTimer").textContent = transcribeTranslations[lang].transcribeTimer;
    document.getElementById("transcription").setAttribute("placeholder", transcribeTranslations[lang].transcriptionPlaceholder);
    document.getElementById("startButton").textContent = transcribeTranslations[lang].startButton;
    document.getElementById("stopButton").textContent = transcribeTranslations[lang].stopButton;
    document.getElementById("pauseResumeButton").textContent = transcribeTranslations[lang].pauseButton;
    document.getElementById("statusMessage").textContent = transcribeTranslations[lang].statusMessage;
    document.getElementById("noteGenerationTitle").textContent = transcribeTranslations[lang].noteGenerationTitle;
    document.getElementById("generateNoteButton").textContent = transcribeTranslations[lang].generateNoteButton;
    document.getElementById("noteTimer").textContent = transcribeTranslations[lang].noteTimer;
    document.getElementById("generatedNote").setAttribute("placeholder", transcribeTranslations[lang].generatedNotePlaceholder);
    document.getElementById("customPromptTitle").textContent = transcribeTranslations[lang].customPromptTitle;
    document.getElementById("promptSlotLabel").textContent = transcribeTranslations[lang].promptSlotLabel;
    document.getElementById("customPrompt").setAttribute("placeholder", transcribeTranslations[lang].customPromptPlaceholder);
    document.getElementById("adUnit").textContent = transcribeTranslations[lang].adUnitText;
    document.getElementById("guideHeading").textContent = transcribeTranslations[lang].guideHeading;
    document.getElementById("guideText").innerHTML = transcribeTranslations[lang].guideText;
  }
  let currentLangTranscribe = localStorage.getItem("siteLanguage") || "en";
  document.getElementById("lang-select-transcribe").value = currentLangTranscribe;
  updateLanguageTranscribe(currentLangTranscribe);
  document.getElementById("lang-select-transcribe").addEventListener("change", function() {
    currentLangTranscribe = this.value;
    localStorage.setItem("siteLanguage", currentLangTranscribe);
    updateLanguageTranscribe(currentLangTranscribe);
  });
  
  function setCookieTranscribe(name, value, days) {
    var expires = "";
    if (days) {
      var date = new Date();
      date.setTime(date.getTime() + (days * 24 * 60 * 60 * 1000));
      expires = "; expires=" + date.toUTCString();
    }
    document.cookie = name + "=" + (value || "") + expires + "; path=/";
  }
  function getCookieTranscribe(name) {
    var nameEQ = name + "=";
    var ca = document.cookie.split(';');
    for (var i = 0; i < ca.length; i++) {
      var c = ca[i];
      while (c.charAt(0) === ' ') c = c.substring(1);
      if (c.indexOf(nameEQ) === 0) return c.substring(nameEQ.length);
    }
    return null;
  }
  function loadAdSenseTranscribe() {
    var script = document.createElement('script');
    script.async = true;
    script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js";
    document.head.appendChild(script);
    (adsbygoogle = window.adsbygoogle || []).push({});
  }
  document.getElementById("cmp-accept").addEventListener("click", function() {
    setCookieTranscribe("user_consent", "accepted", 365);
    document.getElementById("cmp-banner").style.display = "none";
    loadAdSenseTranscribe();
  });
  document.getElementById("cmp-manage").addEventListener("click", function() {
    alert("Here you can manage your cookie and ad preferences.");
  });
  (function() {
    if (getCookieTranscribe("user_consent") === "accepted") {
      document.getElementById("cmp-banner").style.display = "none";
      loadAdSenseTranscribe();
    }
  })();
  
  /* --------------------------
     Recording & Polling Logic (Using Timeslice)
     -------------------------- */
  let mediaStream = null;
  let groupId = null;
  let chunkNumber = 1;
  let manualStop = false;
  let activeRecorder = null;
  let transcriptChunks = {};  // Holds transcript for each chunk
  let pollingIntervals = {};  // Holds polling intervals for each chunk

  function updateStatusMessage(message, color = "#333") {
    const statusMessage = document.getElementById("statusMessage");
    statusMessage.innerText = message;
    statusMessage.style.color = color;
  }

  function stopMicrophone() {
    if (mediaStream) {
      mediaStream.getTracks().forEach(track => track.stop());
      mediaStream = null;
    }
  }

  // Upload chunk (remains unchanged)
  async function uploadChunk(blob, currentChunkNumber, extension, mimeType, isLast = false) {
    const formData = new FormData();
    formData.append("file", blob, `chunk_${currentChunkNumber}.${extension}`);
    formData.append("group_id", groupId);
    formData.append("chunk_number", currentChunkNumber);
    formData.append("api_key", sessionStorage.getItem("openai_api_key"));
    if (isLast) {
      formData.append("last_chunk", "true");
    }
    
    let uploadStartTime = Date.now();
    document.getElementById("uploadTimer").innerText = "Upload Timer: 0 sec";
    let uploadTimerInterval = setInterval(() => {
      let elapsed = Date.now() - uploadStartTime;
      document.getElementById("uploadTimer").innerText = "Upload Timer: " + Math.floor(elapsed / 1000) + " sec";
    }, 1000);
    
    try {
      const response = await fetch(`${backendUrl}/upload`, {
        method: "POST",
        body: formData
      });
      const result = await response.json();
      clearInterval(uploadTimerInterval);
      if (result.session_id) {
        console.log(`Chunk ${currentChunkNumber} uploaded. Session ID: ${result.session_id}`);
      } else {
        updateStatusMessage("Upload error on chunk " + currentChunkNumber + ": " + (result.error || "Unknown error"), "red");
      }
      return result;
    } catch (error) {
      clearInterval(uploadTimerInterval);
      updateStatusMessage("Error uploading chunk " + currentChunkNumber + ": " + error, "red");
      throw error;
    }
  }

  // Poll for transcript of a chunk
  function pollChunkTranscript(chunkNum) {
    const pollStartTime = Date.now();
    pollingIntervals[chunkNum] = setInterval(async () => {
      if (Date.now() - pollStartTime > 60000) {
        clearInterval(pollingIntervals[chunkNum]);
        console.error(`Polling for chunk ${chunkNum} timed out.`);
        return;
      }
      try {
        const response = await fetch(`${backendUrl}/fetch_chunk`, {
          method: "POST",
          headers: {"Content-Type": "application/json"},
          body: JSON.stringify({ session_id: groupId, chunk_number: chunkNum })
        });
        if (response.status === 200) {
          const data = await response.json();
          transcriptChunks[chunkNum] = data.transcript;
          updateTranscriptionOutput();
          clearInterval(pollingIntervals[chunkNum]);
        } else {
          console.log(`Chunk ${chunkNum} transcript not ready yet.`);
        }
      } catch (err) {
        console.error(`Error polling for chunk ${chunkNum}:`, err);
      }
    }, 2000);
  }

  // Merge transcript chunks in order
  function updateTranscriptionOutput() {
    let sortedKeys = Object.keys(transcriptChunks).map(Number).sort((a, b) => a - b);
    let combinedTranscript = "";
    sortedKeys.forEach(key => {
      combinedTranscript += transcriptChunks[key] + " ";
    });
    document.getElementById("transcription").value = combinedTranscript.trim();
  }

  // New recorder function using timeslice
  function startNewRecorder() {
    activeRecorder = new MediaRecorder(mediaStream);
    activeRecorder.ondataavailable = (event) => {
      let actualMimeType = activeRecorder.mimeType || 'audio/mp3';
      let extension = (actualMimeType.indexOf("webm") !== -1) ? "webm" :
                      (actualMimeType.indexOf("ogg") !== -1) ? "ogg" : "mp3";
      let audioBlob = new Blob([event.data], { type: actualMimeType });

      if (manualStop) {
        // Final chunk upload
        uploadChunk(audioBlob, chunkNumber, extension, actualMimeType, true)
          .then(result => {
            if (result && result.session_id) {
              console.log(`Final chunk ${chunkNumber} uploaded. Session ID: ${result.session_id}`);
              pollChunkTranscript(chunkNumber);
            }
          })
          .catch(err => {
            console.error(`Upload error for final chunk ${chunkNumber}:`, err);
          });
      } else {
        // Normal chunk processing
        uploadChunk(audioBlob, chunkNumber, extension, actualMimeType, false)
          .then(result => {
            if (result && result.session_id) {
              console.log(`Chunk ${chunkNumber} uploaded. Session ID: ${result.session_id}`);
              pollChunkTranscript(chunkNumber);
            }
          })
          .catch(err => {
            console.error(`Upload error for chunk ${chunkNumber}:`, err);
          });
        chunkNumber++;
      }
    };

    // Start recorder with timeslice of 2 minutes (120000 ms)
    activeRecorder.start(120000);
    console.log("Recorder started with timeslice 2 minutes");
  }

  // Define backend URL
  const backendUrl = "https://whisper-dev-backend.fly.dev";

  // Start Button Event: Begin recording session
  document.getElementById("startButton").addEventListener("click", async () => {
    manualStop = false;
    if (!groupId) {
      groupId = Date.now().toString();
    }
    chunkNumber = 1;
    transcriptChunks = {};
    try {
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      startNewRecorder();
      document.getElementById("startButton").disabled = true;
      document.getElementById("stopButton").disabled = false;
      document.getElementById("pauseResumeButton").disabled = false;
      document.getElementById("pauseResumeButton").innerText = "Pause Recording";
      updateStatusMessage("Recording...", "red");
      document.getElementById("recordIndicator").style.backgroundColor = "red";
    } catch (error) {
      updateStatusMessage("Microphone access error: " + error, "red");
    }
  });

  // Stop Button Event: End recording session
  document.getElementById("stopButton").addEventListener("click", () => {
    manualStop = true;
    if (activeRecorder && activeRecorder.state !== "inactive") {
      activeRecorder.stop();
    }
    stopMicrophone();
    document.getElementById("startButton").disabled = false;
    document.getElementById("stopButton").disabled = true;
    document.getElementById("pauseResumeButton").disabled = true;
    groupId = null;
    updateStatusMessage("Recording stopped", "blue");
    document.getElementById("recordIndicator").style.backgroundColor = "grey";
  });

  // Pause/Resume Button Event: Stop current chunk and resume recording
  document.getElementById("pauseResumeButton").addEventListener("click", () => {
    if (!activeRecorder) return;
    if (activeRecorder.state === "recording") {
      activeRecorder.stop();
      document.getElementById("pauseResumeButton").innerText = "Resume Recording";
      updateStatusMessage("Recording paused", "orange");
    } else if (activeRecorder.state === "inactive") {
      startNewRecorder();
      document.getElementById("pauseResumeButton").innerText = "Pause Recording";
      updateStatusMessage("Recording resumed", "green");
    }
  });

  /* --------------------------
     Custom Prompt and Note Generation Functionality (Unchanged)
     -------------------------- */
  const promptSlotSelect = document.getElementById("promptSlot");
  const customPromptTextarea = document.getElementById("customPrompt");

  function hashString(str) {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash |= 0;
    }
    return hash.toString();
  }

  function getPromptStorageKey(slot) {
    const apiKey = sessionStorage.getItem("openai_api_key") || "";
    const hashedApiKey = hashString(apiKey);
    return "customPrompt_" + hashedApiKey + "_" + slot;
  }

  function autoResize(textarea) {
    textarea.style.height = "auto";
    textarea.style.height = textarea.scrollHeight + "px";
  }

  function loadPromptForSlot(slot) {
    const key = getPromptStorageKey(slot);
    const storedPrompt = localStorage.getItem(key);
    customPromptTextarea.value = storedPrompt ? storedPrompt : "";
    autoResize(customPromptTextarea);
  }

  customPromptTextarea.addEventListener("input", () => {
    const currentSlot = promptSlotSelect.value;
    const key = getPromptStorageKey(currentSlot);
    localStorage.setItem(key, customPromptTextarea.value);
    autoResize(customPromptTextarea);
  });

  promptSlotSelect.addEventListener("change", () => {
    loadPromptForSlot(promptSlotSelect.value);
  });

  loadPromptForSlot(promptSlotSelect.value);

  // Note Generation Event Listener
  document.getElementById("generateNoteButton").addEventListener("click", async () => {
    const transcriptionText = document.getElementById("transcription").value.trim();
    if (!transcriptionText) {
      alert("No transcription text available.");
      return;
    }
    
    const promptText = customPromptTextarea.value;
    const generatedNoteField = document.getElementById("generatedNote");
    generatedNoteField.value = "";
    
    const noteStartTime = Date.now();
    const noteTimerElement = document.getElementById("noteTimer");
    noteTimerElement.innerText = "Note Generation Timer: 0 sec";
    const noteTimerInterval = setInterval(() => {
      noteTimerElement.innerText = "Note Generation Timer: " + Math.floor((Date.now() - noteStartTime) / 1000) + " sec";
    }, 1000);
    
    const apiKey = sessionStorage.getItem("openai_api_key");
    try {
      const response = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": "Bearer " + apiKey
        },
        body: JSON.stringify({
          model: "gpt-4-turbo",
          messages: [
            { role: "system", content: promptText },
            { role: "user", content: transcriptionText }
          ],
          temperature: 0.7,
          stream: true
        })
      });
      
      const reader = response.body.getReader();
      const decoder = new TextDecoder("utf-8");
      let done = false;
      
      while (!done) {
        const { value, done: doneReading } = await reader.read();
        done = doneReading;
        const chunkValue = decoder.decode(value);
        const lines = chunkValue.split("\n").filter(line => line.trim() !== "");
        for (const line of lines) {
          if (line.startsWith("data: ")) {
            const jsonStr = line.replace("data: ", "").trim();
            if (jsonStr === "[DONE]") {
              done = true;
              break;
            }
            try {
              const parsed = JSON.parse(jsonStr);
              const textChunk = parsed.choices[0].delta?.content || "";
              generatedNoteField.value += textChunk;
              autoResize(generatedNoteField);
            } catch (err) {
              console.error("Stream chunk parsing error:", err);
            }
          }
        }
      }
      clearInterval(noteTimerInterval);
      noteTimerElement.innerText = "Text generation completed!";
    } catch (error) {
      clearInterval(noteTimerInterval);
      generatedNoteField.value = "Error generating note: " + error;
      noteTimerElement.innerText = "";
    }
  });
});
</script>
