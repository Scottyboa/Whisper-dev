<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title id="page-title-transcribe">Transcription Tool with Ads and Guide Overlay</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500&family=Merriweather:wght@300;400&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Roboto', sans-serif;
      background-color: #f8f8f8;
      color: #333;
      margin: 0;
      padding: 0;
    }
    /* Grid Layout */
    .grid-container {
      display: grid;
      grid-template-columns: 250px 1fr 250px;
      height: 100vh;
    }
    /* Left Sidebar */
    .sidebar {
      background-color: #e0e0e0;
      padding: 20px;
      display: flex;
      flex-direction: column;
      gap: 20px;
      position: relative;
    }
    .sidebar button {
      font-size: 18px;
      padding: 15px;
    }
    /* Main Content Area */
    .main-content {
      padding: 20px;
      display: flex;
      flex-direction: column;
      gap: 20px;
      overflow-y: auto;
    }
    /* Recording Area (Top Half) */
    .recording-area {
      border-bottom: 1px solid #ddd;
      padding-bottom: 20px;
    }
    .timer {
      font-size: 18px;
      margin-bottom: 10px;
      color: #333;
    }
    /* Auto-resizing Textareas */
    #transcription, #generatedNote, #customPrompt {
      width: 100%;
      padding: 12px;
      border: 1px solid #ddd;
      border-radius: 10px;
      font-size: 16px;
      box-sizing: border-box;
      margin-bottom: 20px;
      font-family: 'Roboto', sans-serif;
      resize: none;
    }
    /* Allow vertical resize for the transcription output field */
    #transcription {
      resize: vertical;
    }
    #transcription, #generatedNote {
      min-height: 150px;
    }
    #customPrompt {
      min-height: 200px;
    }
    button {
      background-color: #5a9;
      color: #fff;
      border: none;
      border-radius: 10px;
      padding: 12px 20px;
      font-size: 16px;
      cursor: pointer;
      transition: background-color 0.3s, transform 0.1s;
      margin: 10px;
    }
    button:hover {
      background-color: #489;
    }
    button:active {
      transform: scale(0.98);
    }
    /* Bottom Half: Two Columns */
    .bottom-half {
      display: flex;
      gap: 20px;
      flex: 1;
    }
    .column {
      flex: 1;
      display: flex;
      flex-direction: column;
      gap: 10px;
    }
    /* Right Sidebar (Ad Area) */
    .ad-sidebar {
      background-color: #e0e0e0;
      padding: 20px;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    #adUnit {
      width: 100%;
      height: 200px;
      background-color: #ddd;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 18px;
      margin-bottom: 10px;
    }
    /* Guide Overlay */
    #guideView {
      display: none;
      position: fixed;
      top: 10%;
      left: 10%;
      width: 80%;
      height: 80%;
      background: white;
      border: 2px solid #ccc;
      padding: 20px;
      overflow-y: auto;
      z-index: 2000;
    }
    #guideView.active {
      display: block;
    }
    /* Language Dropdown in Sidebar */
    #lang-container-transcribe {
      position: absolute;
      bottom: 20px;
      left: 20px;
      display: flex;
      align-items: center;
      gap: 8px;
    }
    #lang-icon-transcribe {
      width: 28px;
      height: 28px;
    }
    /* Consent Banner */
    #cmp-banner {
      position: fixed;
      bottom: 0;
      left: 0;
      right: 0;
      background: #f8f8f8;
      border-top: 1px solid #ccc;
      padding: 20px;
      text-align: center;
      font-size: 16px;
      z-index: 1000;
      box-shadow: 0 -2px 5px rgba(0,0,0,0.1);
    }
    #cmp-banner button {
      margin-left: 10px;
      padding: 8px 16px;
    }
  </style>
</head>
<body>
  <!-- OpenAI usage hyperlink -->
  <a id="openaiUsageLink" href="https://platform.openai.com/usage" target="_blank">Cost usage overview</a>
  
  <div class="grid-container">
    <!-- Left Sidebar -->
    <aside class="sidebar">
      <button id="btnFunctions">Functions</button>
      <button id="btnGuide">Guide</button>
      <!-- Language dropdown -->
      <div id="lang-container-transcribe">
        <img src="language-icon.png" alt="Language Icon" id="lang-icon-transcribe">
        <select id="lang-select-transcribe">
          <option value="en">English</option>
          <option value="no">Norsk</option>
        </select>
      </div>
    </aside>
    <!-- Main Content -->
    <main class="main-content">
      <!-- Recording Area -->
      <div class="recording-area">
        <h3 id="recordingAreaTitle">Recording Area</h3>
        <div id="recordIndicator" style="width:20px; height:20px; border-radius:50%; background-color:grey; margin:0 auto 10px;"></div>
        <div id="recordTimer" class="timer">Recording Timer: 0 sec</div>
        <div id="uploadTimer" class="timer">Upload Timer: 0 sec</div>
        <div id="transcribeTimer" class="timer">Completion Timer: 0 sec</div>
        <textarea id="transcription" placeholder="Transcription result will appear here..."></textarea>
        <div>
          <button id="startButton">Start Recording</button>
          <button id="stopButton" disabled>Stop/Complete</button>
          <button id="pauseResumeButton" disabled>Pause Recording</button>
        </div>
        <div id="statusMessage">Welcome! Click "Start Recording" to begin.</div>
      </div>
      <!-- Note Generation & Custom Prompt -->
      <div class="bottom-half">
        <div class="column">
          <h3 id="noteGenerationTitle">Note Generation</h3>
          <button id="generateNoteButton">Generate Note</button>
          <div id="noteTimer" class="timer">Note Generation Timer: 0 sec</div>
          <textarea id="generatedNote" readonly placeholder="Generated note will appear here..."></textarea>
        </div>
        <div class="column">
          <h3 id="customPromptTitle">Custom Prompt</h3>
          <label for="promptSlot" id="promptSlotLabel">Prompt Slot:</label>
          <select id="promptSlot">
            <option value="1">1</option>
            <option value="2">2</option>
            <option value="3">3</option>
            <option value="4">4</option>
            <option value="5">5</option>
            <option value="6">6</option>
            <option value="7">7</option>
            <option value="8">8</option>
            <option value="9">9</option>
            <option value="10">10</option>
          </select>
          <textarea id="customPrompt" placeholder="Enter custom prompt here" rows="1"></textarea>
        </div>
      </div>
    </main>
    <!-- Right Sidebar (Ad Area) -->
    <aside class="ad-sidebar">
      <div id="adArea">
        <div id="adUnit">Your Ad Here</div>
      </div>
    </aside>
  </div>
  <!-- Guide Overlay -->
  <div id="guideView">
    <h3 id="guideHeading">Guide & Instructions</h3>
    <p id="guideText">
      Welcome to the Whisper Transcription tool. This application allows medical professionals, therapists, and other practitioners to record and transcribe consultations, as well as generate professional notes using an AI-powered note generator.
      <br><br>
      <strong>How to Use the Functions:</strong>
      <ul>
        <li><strong>Recording:</strong> Click "Start Recording" to begin capturing audio. The recorder will manually stop every 5 minutes (to ensure each audio file is properly finalized) and then immediately restart for the next segment. The recording timer will reflect the overall session duration. Click "Stop/Complete" to end the session.</li>
        <li><strong>Completion:</strong> When you click Stop, the status changes to "Finishing (last part) transcription…" and a completion timer starts. When the full transcript is assembled, the status updates to "Transcription complete!" (in green).</li>
        <li><strong>Note Generation:</strong> After transcription, click "Generate Note" to produce a note based on your transcript and custom prompt.</li>
        <li><strong>Custom Prompt:</strong> On the right, select a prompt slot (1–10) and enter your custom prompt. Your prompt is saved automatically and linked to your API key.</li>
        <li><strong>Guide Toggle:</strong> Use the "Functions" and "Guide" buttons to switch between the functional view and this guide.</li>
      </ul>
      Please click "Functions" to return to the main interface.
    </p>
  </div>
  <!-- Consent Banner -->
  <div id="cmp-banner">
    <span id="consent-text">This website is free to use because we rely solely on ad revenue. We use cookies to personalize ads and improve your experience. By clicking "Accept", you consent to the use of cookies.</span>
    <button id="cmp-accept">Accept</button>
    <button id="cmp-manage">Manage</button>
  </div>
  <script>
    document.addEventListener("DOMContentLoaded", function() {
      /* --------------------------
         Multi-language & Consent Banner Logic
         -------------------------- */
      const transcribeTranslations = {
        en: {
          pageTitle: "Transcription Tool with Ads and Guide Overlay",
          openaiUsageLinkText: "Cost usage overview",
          btnFunctions: "Functions",
          btnGuide: "Guide",
          recordingAreaTitle: "Recording Area",
          recordTimer: "Recording Timer: 0 sec",
          uploadTimer: "Upload Timer: 0 sec",
          transcribeTimer: "Completion Timer: 0 sec",
          transcriptionPlaceholder: "Transcription result will appear here...",
          startButton: "Start Recording",
          stopButton: "Stop/Complete",
          pauseButton: "Pause Recording",
          statusMessage: "Recording…",
          noteGenerationTitle: "Note Generation",
          generateNoteButton: "Generate Note",
          noteTimer: "Note Generation Timer: 0 sec",
          generatedNotePlaceholder: "Generated note will appear here...",
          customPromptTitle: "Custom Prompt",
          promptSlotLabel: "Prompt Slot:",
          customPromptPlaceholder: "Enter custom prompt here",
          adUnitText: "Your Ad Here",
          guideHeading: "Guide & Instructions",
          guideText: `Welcome to the Whisper Transcription tool. This application allows medical professionals, therapists, and other practitioners to record and transcribe consultations, as well as generate professional notes using an AI-powered note generator.
<br><br>
<strong>How to Use the Functions:</strong>
<ul>
  <li><strong>Recording:</strong> Click "Start Recording" to begin capturing audio. The recorder will manually stop every 5 minutes (to ensure each audio file is properly finalized) and then immediately restart for the next segment. The recording timer reflects the overall session duration. Click "Stop/Complete" to end the session.</li>
  <li><strong>Completion:</strong> When you click Stop, the status changes to "Finishing (last part) transcription…" and a completion timer starts. When the full transcript is assembled, the status updates to "Transcription complete!" (in green).</li>
  <li><strong>Note Generation:</strong> After transcription, click "Generate Note" to produce a note based on your transcript and custom prompt.</li>
  <li><strong>Custom Prompt:</strong> On the right, select a prompt slot (1–10) and enter your custom prompt. Your prompt is saved automatically and linked to your API key.</li>
  <li><strong>Guide Toggle:</strong> Use the "Functions" and "Guide" buttons to switch between the functional view and this guide.</li>
</ul>
Please click "Functions" to return to the main interface.`
        },
        no: {
          pageTitle: "Transkripsjonsverktøy med annonser og veiledningsoverlegg",
          openaiUsageLinkText: "Vis OpenAI bruk",
          btnFunctions: "Funksjoner",
          btnGuide: "Veiledning",
          recordingAreaTitle: "Opptaksområde",
          recordTimer: "Opptakstimer: 0 sek",
          uploadTimer: "Opplastningstimer: 0 sek",
          transcribeTimer: "Fullførings-timer: 0 sek",
          transcriptionPlaceholder: "Transkripsjonsresultatet vises her...",
          startButton: "Start opptak",
          stopButton: "Stopp/Fullfør",
          pauseButton: "Pause opptak",
          statusMessage: "Opptak…",
          noteGenerationTitle: "Notatgenerering",
          generateNoteButton: "Generer notat",
          noteTimer: "Notatgenereringstimer: 0 sek",
          generatedNotePlaceholder: "Generert notat vises her...",
          customPromptTitle: "Tilpasset melding",
          promptSlotLabel: "Meldingsplass:",
          customPromptPlaceholder: "Skriv inn tilpasset melding her",
          adUnitText: "Din annonse her",
          guideHeading: "Veiledning og Instruksjoner",
          guideText: `Velkommen til Whisper Transkripsjonsverktøy. Denne applikasjonen lar medisinske fagpersoner, terapeuter og andre utøvere ta opp og transkribere konsultasjoner, samt generere profesjonelle notater ved hjelp av en AI-drevet notatgenerator.
<br><br>
<strong>Slik bruker du verktøyet:</strong>
<ul>
  <li><strong>Opptak:</strong> Klikk på "Start opptak" for å starte opptaket. Recorder stopper manuelt etter 5 minutter for å sikre at hver lydfil er korrekt avsluttet, og deretter starter opptaket for neste segment. Opptakstimeren viser den samlede varigheten. Klikk "Stopp/Fullfør" for å avslutte opptaket.</li>
  <li><strong>Fullføring:</strong> Når du klikker Stopp, endres status til "Avslutter (siste del) transkripsjon…" og en fullføringstimer starter. Når den fullstendige transkripsjonen er mottatt, vises "Transkripsjon ferdig!" i grønn.</li>
  <li><strong>Notatgenerering:</strong> Etter transkripsjonen, klikk "Generer notat" for å lage et notat basert på transkripsjonen og din tilpassede melding.</li>
  <li><strong>Tilpasset melding:</strong> Velg et meldingsfelt (1–10) og skriv inn din tilpassede melding. Meldingen lagres automatisk og knyttes til din API-nøkkel.</li>
  <li><strong>Veiledning:</strong> Bruk knappene "Funksjoner" og "Veiledning" for å bytte mellom verktøysgrensesnittet og denne veiledningen.</li>
</ul>
Klikk "Funksjoner" for å gå tilbake til hovedskjermen.`
        }
      };
      
      function updateLanguageTranscribe(lang) {
        document.getElementById("page-title-transcribe").textContent = transcribeTranslations[lang].pageTitle;
        document.getElementById("openaiUsageLink").textContent = transcribeTranslations[lang].openaiUsageLinkText;
        document.getElementById("btnFunctions").textContent = transcribeTranslations[lang].btnFunctions;
        document.getElementById("btnGuide").textContent = transcribeTranslations[lang].btnGuide;
        document.getElementById("recordingAreaTitle").textContent = transcribeTranslations[lang].recordingAreaTitle;
        document.getElementById("recordTimer").textContent = transcribeTranslations[lang].recordTimer;
        document.getElementById("uploadTimer").textContent = transcribeTranslations[lang].uploadTimer;
        document.getElementById("transcribeTimer").textContent = transcribeTranslations[lang].transcribeTimer;
        document.getElementById("transcription").setAttribute("placeholder", transcribeTranslations[lang].transcriptionPlaceholder);
        document.getElementById("startButton").textContent = transcribeTranslations[lang].startButton;
        document.getElementById("stopButton").textContent = transcribeTranslations[lang].stopButton;
        document.getElementById("pauseResumeButton").textContent = transcribeTranslations[lang].pauseButton;
        document.getElementById("statusMessage").textContent = transcribeTranslations[lang].statusMessage;
        document.getElementById("noteGenerationTitle").textContent = transcribeTranslations[lang].noteGenerationTitle;
        document.getElementById("generateNoteButton").textContent = transcribeTranslations[lang].generateNoteButton;
        document.getElementById("noteTimer").textContent = transcribeTranslations[lang].noteTimer;
        document.getElementById("generatedNote").setAttribute("placeholder", transcribeTranslations[lang].generatedNotePlaceholder);
        document.getElementById("customPromptTitle").textContent = transcribeTranslations[lang].customPromptTitle;
        document.getElementById("promptSlotLabel").textContent = transcribeTranslations[lang].promptSlotLabel;
        document.getElementById("customPrompt").setAttribute("placeholder", transcribeTranslations[lang].customPromptPlaceholder);
        document.getElementById("adUnit").textContent = transcribeTranslations[lang].adUnitText;
        document.getElementById("guideHeading").textContent = transcribeTranslations[lang].guideHeading;
        document.getElementById("guideText").innerHTML = transcribeTranslations[lang].guideText;
      }
      let currentLangTranscribe = localStorage.getItem("siteLanguage") || "en";
      document.getElementById("lang-select-transcribe").value = currentLangTranscribe;
      updateLanguageTranscribe(currentLangTranscribe);
      document.getElementById("lang-select-transcribe").addEventListener("change", function() {
        currentLangTranscribe = this.value;
        localStorage.setItem("siteLanguage", currentLangTranscribe);
        updateLanguageTranscribe(currentLangTranscribe);
      });
      
      /* --------------------------
         Consent Banner & Cookie Management for Transcribe Page
         -------------------------- */
      function setCookieTranscribe(name, value, days) {
        var expires = "";
        if (days) {
          var date = new Date();
          date.setTime(date.getTime() + (days * 24 * 60 * 60 * 1000));
          expires = "; expires=" + date.toUTCString();
        }
        document.cookie = name + "=" + (value || "") + expires + "; path=/";
      }
      function getCookieTranscribe(name) {
        var nameEQ = name + "=";
        var ca = document.cookie.split(';');
        for (var i = 0; i < ca.length; i++) {
          var c = ca[i];
          while (c.charAt(0) === ' ') c = c.substring(1);
          if (c.indexOf(nameEQ) === 0) return c.substring(nameEQ.length);
        }
        return null;
      }
      function loadAdSenseTranscribe() {
        var script = document.createElement('script');
        script.async = true;
        script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js";
        document.head.appendChild(script);
        (adsbygoogle = window.adsbygoogle || []).push({});
      }
      document.getElementById("cmp-accept").addEventListener("click", function() {
        setCookieTranscribe("user_consent", "accepted", 365);
        document.getElementById("cmp-banner").style.display = "none";
        loadAdSenseTranscribe();
      });
      document.getElementById("cmp-manage").addEventListener("click", function() {
        alert("Here you can manage your cookie and ad preferences.");
      });
      (function() {
        if (getCookieTranscribe("user_consent") === "accepted") {
          document.getElementById("cmp-banner").style.display = "none";
          loadAdSenseTranscribe();
        }
      })();
      
      /* --------------------------
         Recording & Polling Logic
         -------------------------- */
      
      // Global variables for recording and polling
      let mediaStream = null;
      let sessionStartTime = 0;  // For overall recording timer
      let recordingTimerInterval;
      let groupId = null;
      let chunkNumber = 1;
      let manualStop = false;  // True if user manually stops recording
      let activeRecorder = null;
      let finalChunkNumber = null; // Set when recording stops
      let finalChunkProcessed = false; // Ensure only one final chunk is processed
      let transcriptChunks = {};  // Holds transcript for each chunk
      let pollingIntervals = {};  // Holds polling intervals for each chunk
      
      // Transcription (completion) timer variables
      let transcriptionTimerStart = 0;
      let transcriptionTimerInterval;
      
      // Update overall recording timer using sessionStartTime.
      function updateRecordingTimer() {
        let elapsed = Date.now() - sessionStartTime;
        document.getElementById("recordTimer").innerText = "Recording Timer: " + formatTime(elapsed);
      }
      
      function stopMicrophone() {
        if (mediaStream) {
          mediaStream.getTracks().forEach(track => track.stop());
          mediaStream = null;
        }
      }
      
      // Modified uploadChunk that uses a captured group ID.
      async function uploadChunk(blob, currentChunkNumber, extension, mimeType, isLast = false, currentGroup) {
        const formData = new FormData();
        formData.append("file", blob, `chunk_${currentChunkNumber}.${extension}`);
        formData.append("group_id", currentGroup);
        formData.append("chunk_number", currentChunkNumber);
        formData.append("api_key", sessionStorage.getItem("openai_api_key"));
        if (isLast) {
          formData.append("last_chunk", "true");
        }
        
        let uploadStartTime = Date.now();
        document.getElementById("uploadTimer").innerText = "Upload Timer: 0 sec";
        let uploadTimerInterval = setInterval(() => {
          let elapsed = Date.now() - uploadStartTime;
          document.getElementById("uploadTimer").innerText = "Upload Timer: " + formatTime(elapsed);
        }, 1000);
        
        try {
          const response = await fetch(`${backendUrl}/upload`, {
            method: "POST",
            body: formData
          });
          const result = await response.json();
          clearInterval(uploadTimerInterval);
          console.log(`Chunk ${currentChunkNumber} uploaded. Session ID: ${result.session_id}`);
          return result;
        } catch (error) {
          clearInterval(uploadTimerInterval);
          console.error("Error uploading chunk", currentChunkNumber, error);
          throw error;
        }
      }
      
      // Modified pollChunkTranscript that captures the group ID.
      function pollChunkTranscript(chunkNum, currentGroup) {
        const pollStartTime = Date.now();
        pollingIntervals[chunkNum] = setInterval(async () => {
          // Only poll if the group for this callback matches the current group.
          if (groupId !== currentGroup) {
            clearInterval(pollingIntervals[chunkNum]);
            return;
          }
          try {
            const response = await fetch(`${backendUrl}/fetch_chunk`, {
              method: "POST",
              headers: {"Content-Type": "application/json"},
              body: JSON.stringify({ session_id: currentGroup, chunk_number: chunkNum })
            });
            if (response.status === 200) {
              const data = await response.json();
              transcriptChunks[chunkNum] = data.transcript;
              updateTranscriptionOutput();
              clearInterval(pollingIntervals[chunkNum]);
              if (finalChunkNumber && chunkNum === finalChunkNumber) {
                clearInterval(transcriptionTimerInterval);
                updateStatusMessage("Transcription complete!", "green");
                document.getElementById("transcribeTimer").innerText = "Completion Timer: " + formatTime(Date.now() - transcriptionTimerStart);
              }
            } else {
              console.log(`Chunk ${chunkNum} transcript not ready yet.`);
            }
          } catch (err) {
            console.error(`Error polling for chunk ${chunkNum}:`, err);
          }
        }, 2000);
      }
      
      function updateTranscriptionOutput() {
        let sortedKeys = Object.keys(transcriptChunks).map(Number).sort((a, b) => a - b);
        let combinedTranscript = "";
        sortedKeys.forEach(key => {
          combinedTranscript += transcriptChunks[key] + " ";
        });
        document.getElementById("transcription").value = combinedTranscript.trim();
      }
      
      // Regular recording approach: manually stop every 5 minutes.
      let chunkTimeout = null;
      function startRegularRecording() {
        // Do NOT reset sessionStartTime here – it was set when the session began.
        clearInterval(recordingTimerInterval);
        updateRecordingTimer();
        recordingTimerInterval = setInterval(updateRecordingTimer, 1000);
        
        activeRecorder = new MediaRecorder(mediaStream);
        activeRecorder.ondataavailable = (event) => {
          clearTimeout(chunkTimeout);
          const currentGroup = groupId;
          let actualMimeType = activeRecorder.mimeType || 'audio/mp3';
          let extension = (actualMimeType.indexOf("webm") !== -1) ? "webm" : ((actualMimeType.indexOf("ogg") !== -1) ? "ogg" : "mp3");
          let audioBlob = new Blob([event.data], { type: actualMimeType });
          
          if (manualStop) {
            // When Stop is clicked, we want to upload the final chunk and update status.
            uploadChunk(audioBlob, chunkNumber, extension, actualMimeType, true, currentGroup)
              .then(result => {
                if (result && result.session_id) {
                  console.log(`Final chunk ${chunkNumber} uploaded. Session ID: ${result.session_id}`);
                  pollChunkTranscript(chunkNumber, currentGroup);
                }
              })
              .catch(err => {
                console.error(`Upload error for final chunk ${chunkNumber}:`, err);
              });
            finalChunkProcessed = true;
            finalChunkNumber = chunkNumber;
            return;
          }
          
          // For regular (non-final) chunks, upload and poll, but do not change the status message.
          uploadChunk(audioBlob, chunkNumber, extension, actualMimeType, false, currentGroup)
            .then(result => {
              if (result && result.session_id) {
                console.log(`Chunk ${chunkNumber} uploaded. Session ID: ${result.session_id}`);
                pollChunkTranscript(chunkNumber, currentGroup);
              }
            })
            .catch(err => {
              console.error(`Upload error for chunk ${chunkNumber}:`, err);
            });
          chunkNumber++;
          
          // Automatically start next chunk if not manually stopped.
          if (!manualStop) {
            startRegularRecording();
          }
        };
        
        activeRecorder.start();
        console.log("Recorder started without timeslice");
        
        // Automatically stop this recorder after 5 minutes (300,000ms).
        chunkTimeout = setTimeout(() => {
          if (activeRecorder && activeRecorder.state === "recording") {
            activeRecorder.stop();
          }
        }, 300000);
      }
      
      const backendUrl = "https://whisper-dev-backend.fly.dev";
      
      // Start Button Event: Always generate a new groupID and new sessionStartTime.
      document.getElementById("startButton").addEventListener("click", async () => {
        manualStop = false;
        finalChunkProcessed = false;
        transcriptChunks = {};
        Object.values(pollingIntervals).forEach(interval => clearInterval(interval));
        pollingIntervals = {};
        try {
          mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          // Generate a new groupID unconditionally.
          groupId = Date.now().toString();
          console.log("New groupID set:", groupId);
          chunkNumber = 1;
          // Set sessionStartTime for the overall recording timer.
          sessionStartTime = Date.now();
          updateRecordingTimer();
          recordingTimerInterval = setInterval(updateRecordingTimer, 1000);
          
          // Clear any existing status and set to "Recording…"
          updateStatusMessage("Recording…", "#333");
          
          startRegularRecording();
      
          document.getElementById("startButton").disabled = true;
          document.getElementById("stopButton").disabled = false;
          document.getElementById("pauseResumeButton").disabled = false;
          document.getElementById("pauseResumeButton").innerText = "Pause Recording";
        } catch (error) {
          updateStatusMessage("Microphone access error: " + error, "red");
        }
      });
      
      // Stop Button Event: User manually stops recording.
      document.getElementById("stopButton").addEventListener("click", () => {
        manualStop = true;
        if (activeRecorder && activeRecorder.state !== "inactive") {
          activeRecorder.stop();
          clearInterval(recordingTimerInterval);
          clearTimeout(chunkTimeout);
        }
        stopMicrophone();
        document.getElementById("startButton").disabled = false;
        document.getElementById("stopButton").disabled = true;
        document.getElementById("pauseResumeButton").disabled = true;
        // When stop is clicked, update status to finishing transcription
        updateStatusMessage("Finishing (last part) transcription…", "blue");
        // Start the transcription timer now.
        transcriptionTimerStart = Date.now();
        transcriptionTimerInterval = setInterval(() => {
          let elapsed = Date.now() - transcriptionTimerStart;
          document.getElementById("transcribeTimer").innerText = "Completion Timer: " + formatTime(elapsed);
        }, 1000);
      });
      
      // Pause/Resume Button Event
      document.getElementById("pauseResumeButton").addEventListener("click", () => {
        if (!activeRecorder) return;
        if (activeRecorder.state === "recording") {
          activeRecorder.pause();
          clearInterval(recordingTimerInterval);
          clearTimeout(chunkTimeout);
          document.getElementById("pauseResumeButton").innerText = "Resume Recording";
          updateStatusMessage("Recording paused", "orange");
        } else if (activeRecorder.state === "paused") {
          activeRecorder.resume();
          // Do not reset sessionStartTime; continue overall recording time.
          recordingTimerInterval = setInterval(updateRecordingTimer, 1000);
          document.getElementById("pauseResumeButton").innerText = "Pause Recording";
          updateStatusMessage("Recording resumed", "green");
          // Restart the 5-minute timeout for the current chunk.
          chunkTimeout = setTimeout(() => {
            if (activeRecorder && activeRecorder.state === "recording") {
              activeRecorder.stop();
            }
          }, 300000);
        }
      });
      
      /* --------------------------
         Custom Prompt and Note Generation Functionality
         -------------------------- */
      
      const promptSlotSelect = document.getElementById("promptSlot");
      const customPromptTextarea = document.getElementById("customPrompt");
      
      function hashString(str) {
        let hash = 0;
        for (let i = 0; i < str.length; i++) {
          const char = str.charCodeAt(i);
          hash = ((hash << 5) - hash) + char;
          hash |= 0;
        }
        return hash.toString();
      }
      
      function getPromptStorageKey(slot) {
        const apiKey = sessionStorage.getItem("openai_api_key") || "";
        const hashedApiKey = hashString(apiKey);
        return "customPrompt_" + hashedApiKey + "_" + slot;
      }
      
      function autoResize(textarea) {
        textarea.style.height = "auto";
        textarea.style.height = textarea.scrollHeight + "px";
      }
      
      function loadPromptForSlot(slot) {
        const key = getPromptStorageKey(slot);
        const storedPrompt = localStorage.getItem(key);
        customPromptTextarea.value = storedPrompt ? storedPrompt : "";
        autoResize(customPromptTextarea);
      }
      
      customPromptTextarea.addEventListener("input", () => {
        const currentSlot = promptSlotSelect.value;
        const key = getPromptStorageKey(currentSlot);
        localStorage.setItem(key, customPromptTextarea.value);
        autoResize(customPromptTextarea);
      });
      
      promptSlotSelect.addEventListener("change", () => {
        loadPromptForSlot(promptSlotSelect.value);
      });
      
      loadPromptForSlot(promptSlotSelect.value);
      
      // Note Generation Event Listener
      document.getElementById("generateNoteButton").addEventListener("click", async () => {
        const transcriptionText = document.getElementById("transcription").value.trim();
        if (!transcriptionText) {
          alert("No transcription text available.");
          return;
        }
        
        const promptText = customPromptTextarea.value;
        const generatedNoteField = document.getElementById("generatedNote");
        generatedNoteField.value = "";
        
        const noteStartTime = Date.now();
        const noteTimerElement = document.getElementById("noteTimer");
        noteTimerElement.innerText = "Note Generation Timer: 0 sec";
        const noteTimerInterval = setInterval(() => {
          noteTimerElement.innerText = "Note Generation Timer: " + formatTime(Date.now() - noteStartTime);
        }, 1000);
        
        const apiKey = sessionStorage.getItem("openai_api_key");
        try {
          const response = await fetch("https://api.openai.com/v1/chat/completions", {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              "Authorization": "Bearer " + apiKey
            },
            body: JSON.stringify({
              model: "gpt-4-turbo",
              messages: [
                { role: "system", content: promptText },
                { role: "user", content: transcriptionText }
              ],
              temperature: 0.7,
              stream: true
            })
          });
          
          const reader = response.body.getReader();
          const decoder = new TextDecoder("utf-8");
          let done = false;
          
          while (!done) {
            const { value, done: doneReading } = await reader.read();
            done = doneReading;
            const chunkValue = decoder.decode(value);
            const lines = chunkValue.split("\n").filter(line => line.trim() !== "");
            for (const line of lines) {
              if (line.startsWith("data: ")) {
                const jsonStr = line.replace("data: ", "").trim();
                if (jsonStr === "[DONE]") {
                  done = true;
                  break;
                }
                try {
                  const parsed = JSON.parse(jsonStr);
                  const textChunk = parsed.choices[0].delta?.content || "";
                  generatedNoteField.value += textChunk;
                  autoResize(generatedNoteField);
                } catch (err) {
                  console.error("Stream chunk parsing error:", err);
                }
              }
            }
          }
          clearInterval(noteTimerInterval);
          noteTimerElement.innerText = "Text generation completed!";
        } catch (error) {
          clearInterval(noteTimerInterval);
          generatedNoteField.value = "Error generating note: " + error;
          noteTimerElement.innerText = "";
        }
      });
      
      // ---------------- End of Custom Prompt & Note Generation ----------------
    });
  </script>
</body>
</html>
