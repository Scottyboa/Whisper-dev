<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Transcription Tool</title>
  <!-- Import Google Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500&family=Merriweather:wght@300;400&display=swap" rel="stylesheet" />
  <style>
    /* Prologue-Inspired Global Styles */
    body {
      font-family: 'Roboto', sans-serif;
      background-color: #f8f8f8;
      color: #333;
      margin: 0;
      padding: 0;
    }
    h2, h3 {
      margin: 0;
      padding: 0;
    }
    h2 {
      font-family: 'Merriweather', serif;
      font-weight: 300;
      font-size: 40px;
      margin-bottom: 20px;
    }
    h3 {
      font-size: 20px;
      margin-bottom: 10px;
    }
    p {
      font-size: 16px;
    }
    /* Buttons, Inputs, and Textareas */
    input[type="text"], textarea, select {
      width: 100%;
      padding: 12px;
      border: 1px solid #ddd;
      border-radius: 10px;
      font-size: 16px;
      box-sizing: border-box;
      transition: border-color 0.3s, box-shadow 0.3s;
      margin-bottom: 20px;
    }
    input[type="text"]:focus, textarea:focus, select:focus {
      border-color: #66afe9;
      box-shadow: 0 0 8px rgba(102,175,233,0.6);
      outline: none;
    }
    button {
      background-color: #5a9;
      color: #fff;
      border: none;
      border-radius: 10px;
      padding: 12px 20px;
      font-size: 16px;
      cursor: pointer;
      transition: background-color 0.3s, transform 0.1s;
      margin: 10px 0;
    }
    button:hover {
      background-color: #489;
    }
    button:active {
      transform: scale(0.98);
    }
    .timer {
      font-size: 18px;
      margin-bottom: 10px;
      color: #333;
    }
    #statusMessage {
      font-size: 16px;
      font-weight: bold;
      margin-top: 10px;
    }
    /* Language Selector (top-right) */
    #langSelect {
      position: absolute;
      top: 10px;
      right: 10px;
      padding: 6px;
      font-size: 14px;
      border: 1px solid #ddd;
      border-radius: 5px;
    }
    /* Grid Layout for entire page */
    .grid-container {
      display: grid;
      grid-template-columns: 250px 1fr;
      height: 100vh;
    }
    /* Sidebar Styles */
    .sidebar {
      background-color: #e0e0e0;
      padding: 20px;
      display: flex;
      flex-direction: column;
      gap: 20px;
      align-items: stretch;
    }
    .sidebar button {
      font-size: 18px;
      padding: 15px;
    }
    /* Main Content Styles */
    .main-content {
      padding: 20px;
      overflow-y: auto;
      display: flex;
      flex-direction: column;
      gap: 20px;
    }
    /* Views */
    .view {
      display: none;
    }
    .view.active {
      display: block;
    }
    /* Recording Area (Top Half) */
    .recording-area {
      border-bottom: 1px solid #ddd;
      padding-bottom: 20px;
    }
    /* Bottom Half: Two Columns */
    .bottom-half {
      display: flex;
      gap: 20px;
      flex: 1;
    }
    .column {
      flex: 1;
      display: flex;
      flex-direction: column;
      gap: 10px;
    }
    /* Ensure textareas have an initial min-height */
    #transcription, #generatedNote, #customPrompt {
      min-height: 150px;
      resize: none;
      overflow: hidden;
    }
  </style>
</head>
<body>
  <select id="langSelect">
    <option value="en">English</option>
    <option value="no">Norsk</option>
  </select>
  <div class="grid-container">
    <!-- Sidebar with Toggle Buttons -->
    <aside class="sidebar">
      <button id="btnFunctions">Functions</button>
      <button id="btnGuide">Guide</button>
    </aside>
    
    <!-- Main Content Area -->
    <main class="main-content">
      <!-- Functions View -->
      <div id="functionsView" class="view active">
        <!-- Top Half: Recording Area -->
        <div class="recording-area">
          <h3>Recording Area</h3>
          <div id="recordIndicator" style="width:20px; height:20px; border-radius:50%; background-color:grey; margin:0 auto 10px;"></div>
          <div id="recordTimer" class="timer">Recording Timer: 0 sec</div>
          <div id="uploadTimer" class="timer">Upload Timer: 0 sec</div>
          <div id="transcribeTimer" class="timer">Transcription Timer: 0 sec</div>
          <textarea id="transcription" placeholder="Transcription result will appear here..."></textarea>
          <div>
            <button id="startButton">Start Recording</button>
            <button id="stopButton" disabled>Stop Recording</button>
            <button id="pauseResumeButton" disabled>Pause Recording</button>
            <button id="transcribeButton" disabled>Transcribe</button>
          </div>
          <div id="statusMessage">Welcome! Click "Start Recording" to begin.</div>
        </div>
        
        <!-- Bottom Half: Note Generation & Custom Prompt -->
        <div class="bottom-half">
          <!-- Left Column: Note Generation -->
          <div class="column">
            <h3>Note Generation</h3>
            <button id="generateNoteButton">Generate Note</button>
            <div id="noteTimer" class="timer">Note Generation Timer: 0 sec</div>
            <textarea id="generatedNote" readonly placeholder="Generated note will appear here..."></textarea>
          </div>
          <!-- Right Column: Custom Prompt -->
          <div class="column">
            <h3>Custom Prompt</h3>
            <label for="promptSlot">Prompt Slot:</label>
            <select id="promptSlot">
              <option value="1">1</option>
              <option value="2">2</option>
              <option value="3">3</option>
              <option value="4">4</option>
              <option value="5">5</option>
              <option value="6">6</option>
              <option value="7">7</option>
              <option value="8">8</option>
              <option value="9">9</option>
              <option value="10">10</option>
            </select>
            <textarea id="customPrompt" placeholder="Enter custom prompt here" rows="1"></textarea>
          </div>
        </div>
      </div>
      
      <!-- Guide View -->
      <div id="guideView" class="view">
        <h3>Guide & Instructions</h3>
        <p>
          Welcome to the Whisper Transcription tool. This application allows medical professionals, therapists, psychologists, and physiotherapists to record and transcribe consultations, and generate professional notes using AI.
        </p>
        <h4>How to Use the Tool:</h4>
        <ul style="text-align:left; max-width:600px; margin:0 auto;">
          <li><strong>Recording:</strong> Click "Start Recording" to capture audio. Use "Stop Recording" to end and upload your recording.</li>
          <li><strong>Transcription:</strong> Once uploaded, click "Transcribe" to convert speech to text. The transcription appears above.</li>
          <li><strong>Note Generation:</strong> After transcription, click "Generate Note" to create a professional note using your custom prompt. A timer displays the note generation time, and the result appears in the generated note area.</li>
          <li><strong>Custom Prompt:</strong> Select a prompt slot (1–10) and enter your custom prompt. Your prompt is saved automatically (associated with your API key).</li>
        </ul>
        <p>
          <strong>Security & Confidentiality:</strong> All recordings, transcriptions, and generated notes are automatically deleted after 15 minutes. Nothing is stored permanently—your data remains confidential and secure.
        </p>
        <p>
          Please ensure you have entered your API key on the index page before using the tool.
        </p>
      </div>
    </main>
  </div>
  
  <script>
    // Translation strings for transcribe page (for static texts)
    const translations = {
      en: {
        functionsTitle: "Recording Area",
        noteGenTitle: "Note Generation",
        customPromptTitle: "Custom Prompt",
        guideTitle: "Guide & Instructions",
        guideInstructions: `<ul style="text-align:left; max-width:600px; margin:0 auto;">
          <li><strong>Recording:</strong> Click "Start Recording" to capture audio. Use "Stop Recording" to end and upload your recording.</li>
          <li><strong>Transcription:</strong> Once uploaded, click "Transcribe" to convert speech to text. The transcription appears above.</li>
          <li><strong>Note Generation:</strong> After transcription, click "Generate Note" to create a professional note using your custom prompt. A timer displays the note generation time, and the result appears in the generated note area.</li>
          <li><strong>Custom Prompt:</strong> Select a prompt slot (1–10) and enter your custom prompt. Your prompt is saved automatically (associated with your API key).</li>
        </ul>
        <p><strong>Security & Confidentiality:</strong> All recordings, transcriptions, and generated notes are automatically deleted after 15 minutes. Nothing is stored permanently—your data remains confidential and secure.</p>
        <p>Please ensure you have entered your API key on the index page before using the tool.</p>`
      },
      no: {
        functionsTitle: "Opptaksområde",
        noteGenTitle: "Notegenerering",
        customPromptTitle: "Egendefinert prompt",
        guideTitle: "Veiledning & Instruksjoner",
        guideInstructions: `<ul style="text-align:left; max-width:600px; margin:0 auto;">
          <li><strong>Opptak:</strong> Klikk "Start Recording" for å ta opp lyd. Bruk "Stop Recording" for å avslutte og laste opp opptaket.</li>
          <li><strong>Transkripsjon:</strong> Når opptaket er lastet opp, klikker du "Transcribe" for å konvertere tale til tekst. Transkripsjonen vises ovenfor.</li>
          <li><strong>Notegenerering:</strong> Etter transkripsjon, klikk "Generate Note" for å lage et profesjonelt notat ved hjelp av din egendefinerte prompt. En timer viser genereringstiden, og resultatet vises i notatområdet.</li>
          <li><strong>Egendefinert prompt:</strong> Velg en prompt-slot (1–10) og skriv inn din egendefinerte prompt. Din prompt lagres automatisk (assosiert med din API-nøkkel).</li>
        </ul>
        <p><strong>Sikkerhet & Konfidensialitet:</strong> Alle opptak, transkripsjoner og genererte notater slettes automatisk etter 15 minutter. Ingenting lagres permanent—dine data forblir konfidensielle og sikre.</p>
        <p>Vennligst sørg for at du har skrevet inn din API-nøkkel på index-siden før du bruker verktøyet.</p>`
      }
    };

    // Set language based on saved selection (default to English)
    let currentLang = localStorage.getItem("siteLanguage") || "en";
    
    // Function to update language on transcribe page (static texts)
    function updateTranscribeLanguage(lang) {
      // Update sidebar toggle button texts if needed
      // (In this example, the sidebar buttons remain language-neutral.)
      // Update guide view content
      document.querySelector("#guideView h3").innerText = translations[lang].guideTitle;
      document.querySelector("#guideView").innerHTML = 
        `<h3>${translations[lang].guideTitle}</h3>` +
        translations[lang].guideInstructions;
      // Update headings in functions view
      document.querySelector(".recording-area h3").innerText = (lang === "en") ? "Recording Area" : "Opptaksområde";
      document.querySelector(".left-column h3").innerText = (lang === "en") ? translations[lang].noteGenTitle : translations[lang].noteGenTitle;
      document.querySelector(".right-column h3").innerText = (lang === "en") ? translations[lang].customPromptTitle : translations[lang].customPromptTitle;
    }
    
    updateTranscribeLanguage(currentLang);
    
    // Language selector (same as in index.html)
    const langSelect = document.getElementById("langSelect");
    langSelect.value = currentLang;
    langSelect.addEventListener("change", (e) => {
      currentLang = e.target.value;
      localStorage.setItem("siteLanguage", currentLang);
      updateTranscribeLanguage(currentLang);
    });
    
    // Retrieve API key from sessionStorage
    const apiKey = sessionStorage.getItem("openai_api_key");
    if (!apiKey) {
      alert("API key is missing. Please re-enter it.");
      window.location.href = "index.html";
    }
    
    // Hash API key for localStorage keys
    function hashString(str) {
      let hash = 0;
      for (let i = 0; i < str.length; i++) {
        const char = str.charCodeAt(i);
        hash = ((hash << 5) - hash) + char;
        hash |= 0;
      }
      return hash.toString();
    }
    const hashedApiKey = hashString(apiKey);
    
    function getPromptStorageKey(slot) {
      return "customPrompt_" + hashedApiKey + "_" + slot;
    }
    
    // Custom Prompt Section: load and save
    const promptSlotSelect = document.getElementById("promptSlot");
    const customPromptTextarea = document.getElementById("customPrompt");
    
    function loadPromptForSlot(slot) {
      const key = getPromptStorageKey(slot);
      const storedPrompt = localStorage.getItem(key);
      customPromptTextarea.value = storedPrompt ? storedPrompt : "";
      autoResize(customPromptTextarea);
    }
    customPromptTextarea.addEventListener("input", () => {
      const currentSlot = promptSlotSelect.value;
      const key = getPromptStorageKey(currentSlot);
      localStorage.setItem(key, customPromptTextarea.value);
      autoResize(customPromptTextarea);
    });
    promptSlotSelect.addEventListener("change", () => {
      loadPromptForSlot(promptSlotSelect.value);
    });
    function autoResize(textarea) {
      textarea.style.height = "auto";
      textarea.style.height = textarea.scrollHeight + "px";
    }
    loadPromptForSlot(promptSlotSelect.value);
    
    // Backend URL and Recording Variables
    const backendUrl = "https://whisper-online.fly.dev";
    let mediaRecorder;
    let audioChunks = [];
    let sessionId = "";
    let recordingStartTime = 0;
    let recordingTimerInterval;
    let uploadTimerInterval;
    let transcriptionTimerInterval;
    let isPaused = false;
    let pausedTimeAccumulated = 0;
    let pauseStartTime = 0;
    let autoDeleteTimeout;
    let uploadStartTime = 0;
    let mediaStream = null;
    
    function updateStatusMessage(message, color = "#333") {
      const statusMessage = document.getElementById("statusMessage");
      statusMessage.innerText = message;
      statusMessage.style.color = color;
    }
    function updateRecordingTimer() {
      let elapsed = Date.now() - recordingStartTime - pausedTimeAccumulated;
      document.getElementById("recordTimer").innerText = "Recording Timer: " + formatTime(elapsed);
    }
    function updateUploadTimer() {
      let elapsed = Date.now() - uploadStartTime;
      document.getElementById("uploadTimer").innerText = "Upload Timer: " + formatTime(elapsed);
    }
    
    async function handleStop() {
      clearInterval(recordingTimerInterval);
      updateStatusMessage("Uploading audio... Please wait.", "blue");
      const audioBlob = new Blob(audioChunks, { type: 'audio/mp3' });
      const formData = new FormData();
      formData.append("file", audioBlob, "recorded.mp3");
      uploadStartTime = Date.now();
      document.getElementById("uploadTimer").innerText = "Upload Timer: 0 sec";
      uploadTimerInterval = setInterval(updateUploadTimer, 1000);
      try {
        const response = await fetch(`${backendUrl}/upload`, {
          method: "POST",
          body: formData
        });
        const result = await response.json();
        clearInterval(uploadTimerInterval);
        if (result.session_id) {
          sessionId = result.session_id;
          document.getElementById("recordIndicator").style.backgroundColor = "green";
          updateStatusMessage("Audio uploaded! Ready for transcription.", "green");
          document.getElementById("transcribeButton").disabled = false;
          clearTimeout(autoDeleteTimeout);
          autoDeleteTimeout = setTimeout(() => {
            sessionId = "";
            updateStatusMessage("Recording automatically deleted.", "green");
          }, 900000);
        } else {
          updateStatusMessage("Upload error: " + (result.error || "Unknown error"), "red");
        }
      } catch (error) {
        updateStatusMessage("Error uploading file: " + error, "red");
      }
      stopMicrophone();
    }
    function stopMicrophone() {
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
        mediaStream = null;
      }
    }
    
    document.getElementById("startButton").addEventListener("click", async () => {
      clearTimeout(autoDeleteTimeout);
      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(mediaStream);
        audioChunks = [];
        isPaused = false;
        pausedTimeAccumulated = 0;
        recordingStartTime = Date.now();
        updateRecordingTimer();
        recordingTimerInterval = setInterval(updateRecordingTimer, 1000);
        mediaRecorder.ondataavailable = event => {
          if (event.data.size > 0) {
            audioChunks.push(event.data);
          }
        };
        mediaRecorder.onstop = handleStop;
        mediaRecorder.start();
        document.getElementById("startButton").disabled = true;
        document.getElementById("stopButton").disabled = false;
        document.getElementById("pauseResumeButton").disabled = false;
        document.getElementById("pauseResumeButton").innerText = "Pause Recording";
        document.getElementById("recordIndicator").style.backgroundColor = "red";
        updateStatusMessage("Recording in progress...");
      } catch (error) {
        updateStatusMessage("Microphone access error: " + error, "red");
      }
    });
    
    document.getElementById("stopButton").addEventListener("click", () => {
      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
        document.getElementById("startButton").disabled = false;
        document.getElementById("stopButton").disabled = true;
        document.getElementById("pauseResumeButton").disabled = true;
      }
    });
    
    document.getElementById("pauseResumeButton").addEventListener("click", () => {
      if (!mediaRecorder) return;
      if (mediaRecorder.state === "recording") {
        mediaRecorder.pause();
        pauseStartTime = Date.now();
        clearInterval(recordingTimerInterval);
        document.getElementById("pauseResumeButton").innerText = "Resume Recording";
        updateStatusMessage("Recording paused", "orange");
      } else if (mediaRecorder.state === "paused") {
        mediaRecorder.resume();
        pausedTimeAccumulated += Date.now() - pauseStartTime;
        recordingTimerInterval = setInterval(updateRecordingTimer, 1000);
        document.getElementById("pauseResumeButton").innerText = "Pause Recording";
        updateStatusMessage("Recording resumed", "green");
      }
    });
    
    document.getElementById("transcribeButton").addEventListener("click", async () => {
      const storedApiKey = sessionStorage.getItem("openai_api_key");
      if (!storedApiKey || !sessionId) {
        updateStatusMessage("API key or recording missing.", "red");
        return;
      }
      updateStatusMessage("Transcription in progress...", "blue");
      const transcriptionStart = Date.now();
      transcriptionTimerInterval = setInterval(() => {
        document.getElementById("transcribeTimer").innerText = "Transcription Timer: " + Math.floor((Date.now() - transcriptionStart) / 1000) + " s";
      }, 1000);
      try {
        const response = await fetch(`${backendUrl}/transcribe`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ api_key: storedApiKey, session_id: sessionId })
        });
        const result = await response.json();
        clearInterval(transcriptionTimerInterval);
        if (result.transcription) {
          updateStatusMessage("Transcription complete!", "green");
          document.getElementById("transcription").value = result.transcription;
        } else {
          updateStatusMessage("No transcription available.", "red");
        }
      } catch (error) {
        updateStatusMessage("Transcription error: " + error, "red");
      }
    });
    
    // Note Generation with Streaming and Timer
    document.getElementById("generateNoteButton").addEventListener("click", async () => {
      const transcriptionText = document.getElementById("transcription").value.trim();
      if (!transcriptionText) {
        alert("No transcription text available.");
        return;
      }
      const promptText = customPromptTextarea.value;
      const generatedNoteField = document.getElementById("generatedNote");
      generatedNoteField.value = "";
      const noteStartTime = Date.now();
      const noteTimerElement = document.getElementById("noteTimer");
      noteTimerElement.innerText = "Note Generation Timer: 0 sec";
      const noteTimerInterval = setInterval(() => {
        noteTimerElement.innerText = "Note Generation Timer: " + formatTime(Date.now() - noteStartTime);
      }, 1000);
      try {
        const response = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + apiKey
          },
          body: JSON.stringify({
            model: "gpt-4",
            messages: [
              { role: "system", content: promptText },
              { role: "user", content: transcriptionText }
            ],
            temperature: 0.7,
            stream: true
          })
        });
        const reader = response.body.getReader();
        const decoder = new TextDecoder("utf-8");
        let done = false;
        while (!done) {
          const { value, done: doneReading } = await reader.read();
          done = doneReading;
          const chunkValue = decoder.decode(value);
          const lines = chunkValue.split("\n").filter(line => line.trim() !== "");
          for (const line of lines) {
            if (line.startsWith("data: ")) {
              const jsonStr = line.replace("data: ", "").trim();
              if (jsonStr === "[DONE]") {
                done = true;
                break;
              }
              try {
                const parsed = JSON.parse(jsonStr);
                const textChunk = parsed.choices[0].delta?.content || "";
                generatedNoteField.value += textChunk;
                autoResize(generatedNoteField);
              } catch (err) {
                console.error("Stream chunk parsing error:", err);
              }
            }
          }
        }
        clearInterval(noteTimerInterval);
        noteTimerElement.innerText = "Text generation completed!";
      } catch (error) {
        clearInterval(noteTimerInterval);
        generatedNoteField.value = "Error generating note: " + error;
        noteTimerElement.innerText = "";
      }
    });
  </script>
</body>
</html>
